/*
 * Falcon signature verification.
 *
 * ==========================(LICENSE BEGIN)============================
 *
 * Copyright (c) 2017  Falcon Project
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * ===========================(LICENSE END)=============================
 *
 * @author   Thomas Pornin <thomas.pornin@nccgroup.trust>
 */

#include "internal.h"

/* ===================================================================== */
/*
 * Constants for NTT.
 *
 * Binary case:
 *   n = 2^logn  (2 <= n <= 1024)
 *   phi = X^n + 1
 *   q = 12289
 *
 * Ternary case:
 *   n = 1.5*2^n  (6 <= n <= 768)
 *   phi = X^n - X^(n/2) + 1
 *   q = 18433
 *
 * In both cases:
 *   q0i = -1/q mod 2^16
 *   R = 2^16 mod q
 *   R2 = 2^32 mod q
 */

#define Qb     12289
#define Q0Ib   12287
#define Rb      4091
#define R2b    10952

#define Qt     18433
#define Q0It   18431
#define Rt     10237
#define R2t     4564

/*
 * Inverse of n = 1.5*2^logn modulo q, for the ternary case. Values are
 * in Montogmery representation. This is defined only for logn from 2 to 9.
 */
static const uint16_t INVNQt[] = {
	0, 0, 17067, 17750, 8875, 13654, 6827, 12630, 6315, 12374
};

/*
 * Table for NTT, binary case:
 *   GMb[x] = R*(g^rev(x)) mod q
 * where g = 7 (it is a 2048-th primitive root of 1 modulo q)
 * and rev() is the bit-reversal function over 10 bits.
 */
static const uint16_t GMb[] = {
	 4091,  7888, 11060, 11208,  6960,  4342,  6275,  9759,
	 1591,  6399,  9477,  5266,   586,  5825,  7538,  9710,
	 1134,  6407,  1711,   965,  7099,  7674,  3743,  6442,
	10414,  8100,  1885,  1688,  1364, 10329, 10164,  9180,
	12210,  6240,   997,   117,  4783,  4407,  1549,  7072,
	 2829,  6458,  4431,  8877,  7144,  2564,  5664,  4042,
	12189,   432, 10751,  1237,  7610,  1534,  3983,  7863,
	 2181,  6308,  8720,  6570,  4843,  1690,    14,  3872,
	 5569,  9368, 12163,  2019,  7543,  2315,  4673,  7340,
	 1553,  1156,  8401, 11389,  1020,  2967, 10772,  7045,
	 3316, 11236,  5285, 11578, 10637, 10086,  9493,  6180,
	 9277,  6130,  3323,   883, 10469,   489,  1502,  2851,
	11061,  9729,  2742, 12241,  4970, 10481, 10078,  1195,
	  730,  1762,  3854,  2030,  5892, 10922,  9020,  5274,
	 9179,  3604,  3782, 10206,  3180,  3467,  4668,  2446,
	 7613,  9386,   834,  7703,  6836,  3403,  5351, 12276,
	 3580,  1739, 10820,  9787, 10209,  4070, 12250,  8525,
	10401,  2749,  7338, 10574,  6040,   943,  9330,  1477,
	 6865,  9668,  3585,  6633, 12145,  4063,  3684,  7680,
	 8188,  6902,  3533,  9807,  6090,   727, 10099,  7003,
	 6945,  1949,  9731, 10559,  6057,   378,  7871,  8763,
	 8901,  9229,  8846,  4551,  9589, 11664,  7630,  8821,
	 5680,  4956,  6251,  8388, 10156,  8723,  2341,  3159,
	 1467,  5460,  8553,  7783,  2649,  2320,  9036,  6188,
	  737,  3698,  4699,  5753,  9046,  3687,    16,   914,
	 5186, 10531,  4552,  1964,  3509,  8436,  7516,  5381,
	10733,  3281,  7037,  1060,  2895,  7156,  8887,  5357,
	 6409,  8197,  2962,  6375,  5064,  6634,  5625,   278,
	  932, 10229,  8927,  7642,   351,  9298,   237,  5858,
	 7692,  3146, 12126,  7586,  2053, 11285,  3802,  5204,
	 4602,  1748, 11300,   340,  3711,  4614,   300, 10993,
	 5070, 10049, 11616, 12247,  7421, 10707,  5746,  5654,
	 3835,  5553,  1224,  8476,  9237,  3845,   250, 11209,
	 4225,  6326,  9680, 12254,  4136,  2778,   692,  8808,
	 6410,  6718, 10105, 10418,  3759,  7356, 11361,  8433,
	 6437,  3652,  6342,  8978,  5391,  2272,  6476,  7416,
	 8418, 10824, 11986,  5733,   876,  7030,  2167,  2436,
	 3442,  9217,  8206,  4858,  5964,  2746,  7178,  1434,
	 7389,  8879, 10661, 11457,  4220,  1432, 10832,  4328,
	 8557,  1867,  9454,  2416,  3816,  9076,   686,  5393,
	 2523,  4339,  6115,   619,   937,  2834,  7775,  3279,
	 2363,  7488,  6112,  5056,   824, 10204, 11690,  1113,
	 2727,  9848,   896,  2028,  5075,  2654, 10464,  7884,
	12169,  5434,  3070,  6400,  9132, 11672, 12153,  4520,
	 1273,  9739, 11468,  9937, 10039,  9720,  2262,  9399,
	11192,   315,  4511,  1158,  6061,  6751, 11865,   357,
	 7367,  4550,   983,  8534,  8352, 10126,  7530,  9253,
	 4367,  5221,  3999,  8777,  3161,  6990,  4130, 11652,
	 3374, 11477,  1753,   292,  8681,  2806, 10378, 12188,
	 5800, 11811,  3181,  1988,  1024,  9340,  2477, 10928,
	 4582,  6750,  3619,  5503,  5233,  2463,  8470,  7650,
	 7964,  6395,  1071,  1272,  3474, 11045,  3291, 11344,
	 8502,  9478,  9837,  1253,  1857,  6233,  4720, 11561,
	 6034,  9817,  3339,  1797,  2879,  6242,  5200,  2114,
	 7962,  9353, 11363,  5475,  6084,  9601,  4108,  7323,
	10438,  9471,  1271,   408,  6911,  3079,   360,  8276,
	11535,  9156,  9049, 11539,   850,  8617,   784,  7919,
	 8334, 12170,  1846, 10213, 12184,  7827, 11903,  5600,
	 9779,  1012,   721,  2784,  6676,  6552,  5348,  4424,
	 6816,  8405,  9959,  5150,  2356,  5552,  5267,  1333,
	 8801,  9661,  7308,  5788,  4910,   909, 11613,  4395,
	 8238,  6686,  4302,  3044,  2285, 12249,  1963,  9216,
	 4296, 11918,   695,  4371,  9793,  4884,  2411, 10230,
	 2650,   841,  3890, 10231,  7248,  8505, 11196,  6688,
	 4059,  6060,  3686,  4722, 11853,  5816,  7058,  6868,
	11137,  7926,  4894, 12284,  4102,  3908,  3610,  6525,
	 7938,  7982, 11977,  6755,   537,  4562,  1623,  8227,
	11453,  7544,   906, 11816,  9548, 10858,  9703,  2815,
	11736,  6813,  6979,   819,  8903,  6271, 10843,   348,
	 7514,  8339,  6439,   694,   852,  5659,  2781,  3716,
	11589,  3024,  1523,  8659,  4114, 10738,  3303,  5885,
	 2978,  7289, 11884,  9123,  9323, 11830,    98,  2526,
	 2116,  4131, 11407,  1844,  3645,  3916,  8133,  2224,
	10871,  8092,  9651,  5989,  7140,  8480,  1670,   159,
	10923,  4918,   128,  7312,   725,  9157,  5006,  6393,
	 3494,  6043, 10972,  6181, 11838,  3423, 10514,  7668,
	 3693,  6658,  6905, 11953, 10212, 11922,  9101,  8365,
	 5110,    45,  2400,  1921,  4377,  2720,  1695,    51,
	 2808,   650,  1896,  9997,  9971, 11980,  8098,  4833,
	 4135,  4257,  5838,  4765, 10985, 11532,   590, 12198,
	  482, 12173,  2006,  7064, 10018,  3912, 12016, 10519,
	11362,  6954,  2210,   284,  5413,  6601,  3865, 10339,
	11188,  6231,   517,  9564, 11281,  3863,  1210,  4604,
	 8160, 11447,   153,  7204,  5763,  5089,  9248, 12154,
	11748,  1354,  6672,   179,  5532,  2646,  5941, 12185,
	  862,  3158,   477,  7279,  5678,  7914,  4254,   302,
	 2893, 10114,  6890,  9560,  9647, 11905,  4098,  9824,
	10269,  1353, 10715,  5325,  6254,  3951,  1807,  6449,
	 5159,  1308,  8315,  3404,  1877,  1231,   112,  6398,
	11724, 12272,  7286,  1459, 12274,  9896,  3456,   800,
	 1397, 10678,   103,  7420,  7976,   936,   764,   632,
	 7996,  8223,  8445,  7758, 10870,  9571,  2508,  1946,
	 6524, 10158,  1044,  4338,  2457,  3641,  1659,  4139,
	 4688,  9733, 11148,  3946,  2082,  5261,  2036, 11850,
	 7636, 12236,  5366,  2380,  1399,  7720,  2100,  3217,
	10912,  8898,  7578, 11995,  2791,  1215,  3355,  2711,
	 2267,  2004,  8568, 10176,  3214,  2337,  1750,  4729,
	 4997,  7415,  6315, 12044,  4374,  7157,  4844,   211,
	 8003, 10159,  9290, 11481,  1735,  2336,  5793,  9875,
	 8192,   986,  7527,  1401,   870,  3615,  8465,  2756,
	 9770,  2034, 10168,  3264,  6132,    54,  2880,  4763,
	11805,  3074,  8286,  9428,  4881,  6933,  1090, 10038,
	 2567,   708,   893,  6465,  4962, 10024,  2090,  5718,
	10743,   780,  4733,  4623,  2134,  2087,  4802,   884,
	 5372,  5795,  5938,  4333,  6559,  7549,  5269, 10664,
	 4252,  3260,  5917, 10814,  5768,  9983,  8096,  7791,
	 6800,  7491,  6272,  1907, 10947,  6289, 11803,  6032,
	11449,  1171,  9201,  7933,  2479,  7970, 11337,  7062,
	 8911,  6728,  6542,  8114,  8828,  6595,  3545,  4348,
	 4610,  2205,  6999,  8106,  5560, 10390,  9321,  2499,
	 2413,  7272,  6881, 10582,  9308,  9437,  3554,  3326,
	 5991, 11969,  3415, 12283,  9838, 12063,  4332,  7830,
	11329,  6605, 12271,  2044, 11611,  7353, 11201, 11582,
	 3733,  8943,  9978,  1627,  7168,  3935,  5050,  2762,
	 7496, 10383,   755,  1654, 12053,  4952, 10134,  4394,
	 6592,  7898,  7497,  8904, 12029,  3581, 10748,  5674,
	10358,  4901,  7414,  8771,   710,  6764,  8462,  7193,
	 5371,  7274, 11084,   290,  7864,  6827, 11822,  2509,
	 6578,  4026,  5807,  1458,  5721,  5762,  4178,  2105,
	11621,  4852,  8897,  2856, 11510,  9264,  2520,  8776,
	 7011,  2647,  1898,  7039,  5950, 11163,  5488,  6277,
	 9182, 11456,   633, 10046, 11554,  5633,  9587,  2333,
	 7008,  7084,  5047,  7199,  9865,  8997,   569,  6390,
	10845,  9679,  8268, 11472,  4203,  1997,     2,  9331,
	  162,  6182,  2000,  3649,  9792,  6363,  7557,  6187,
	 8510,  9935,  5536,  9019,  3706, 12009,  1452,  3067,
	 5494,  9692,  4865,  6019,  7106,  9610,  4588, 10165,
	 6261,  5887,  2652, 10172,  1580, 10379,  4638,  9949
};

/*
 * Table for inverse NTT, binary case:
 *   iGMb[x] = R*((1/g)^rev(x)) mod q
 * Since g = 7, 1/g = 8778 mod 12289.
 */
static const uint16_t iGMb[] = {
	 4091,  4401,  1081,  1229,  2530,  6014,  7947,  5329,
	 2579,  4751,  6464, 11703,  7023,  2812,  5890, 10698,
	 3109,  2125,  1960, 10925, 10601, 10404,  4189,  1875,
	 5847,  8546,  4615,  5190, 11324, 10578,  5882, 11155,
	 8417, 12275, 10599,  7446,  5719,  3569,  5981, 10108,
	 4426,  8306, 10755,  4679, 11052,  1538, 11857,   100,
	 8247,  6625,  9725,  5145,  3412,  7858,  5831,  9460,
	 5217, 10740,  7882,  7506, 12172, 11292,  6049,    79,
	   13,  6938,  8886,  5453,  4586, 11455,  2903,  4676,
	 9843,  7621,  8822,  9109,  2083,  8507,  8685,  3110,
	 7015,  3269,  1367,  6397, 10259,  8435, 10527, 11559,
	11094,  2211,  1808,  7319,    48,  9547,  2560,  1228,
	 9438, 10787, 11800,  1820, 11406,  8966,  6159,  3012,
	 6109,  2796,  2203,  1652,   711,  7004,  1053,  8973,
	 5244,  1517,  9322, 11269,   900,  3888, 11133, 10736,
	 4949,  7616,  9974,  4746, 10270,   126,  2921,  6720,
	 6635,  6543,  1582,  4868,    42,   673,  2240,  7219,
	 1296, 11989,  7675,  8578, 11949,   989, 10541,  7687,
	 7085,  8487,  1004, 10236,  4703,   163,  9143,  4597,
	 6431, 12052,  2991, 11938,  4647,  3362,  2060, 11357,
	12011,  6664,  5655,  7225,  5914,  9327,  4092,  5880,
	 6932,  3402,  5133,  9394, 11229,  5252,  9008,  1556,
	 6908,  4773,  3853,  8780, 10325,  7737,  1758,  7103,
	11375, 12273,  8602,  3243,  6536,  7590,  8591, 11552,
	 6101,  3253,  9969,  9640,  4506,  3736,  6829, 10822,
	 9130,  9948,  3566,  2133,  3901,  6038,  7333,  6609,
	 3468,  4659,   625,  2700,  7738,  3443,  3060,  3388,
	 3526,  4418, 11911,  6232,  1730,  2558, 10340,  5344,
	 5286,  2190, 11562,  6199,  2482,  8756,  5387,  4101,
	 4609,  8605,  8226,   144,  5656,  8704,  2621,  5424,
	10812,  2959, 11346,  6249,  1715,  4951,  9540,  1888,
	 3764,    39,  8219,  2080,  2502,  1469, 10550,  8709,
	 5601,  1093,  3784,  5041,  2058,  8399, 11448,  9639,
	 2059,  9878,  7405,  2496,  7918, 11594,   371,  7993,
	 3073, 10326,    40, 10004,  9245,  7987,  5603,  4051,
	 7894,   676, 11380,  7379,  6501,  4981,  2628,  3488,
	10956,  7022,  6737,  9933,  7139,  2330,  3884,  5473,
	 7865,  6941,  5737,  5613,  9505, 11568, 11277,  2510,
	 6689,   386,  4462,   105,  2076, 10443,   119,  3955,
	 4370, 11505,  3672, 11439,   750,  3240,  3133,   754,
	 4013, 11929,  9210,  5378, 11881, 11018,  2818,  1851,
	 4966,  8181,  2688,  6205,  6814,   926,  2936,  4327,
	10175,  7089,  6047,  9410, 10492,  8950,  2472,  6255,
	  728,  7569,  6056, 10432, 11036,  2452,  2811,  3787,
	  945,  8998,  1244,  8815, 11017, 11218,  5894,  4325,
	 4639,  3819,  9826,  7056,  6786,  8670,  5539,  7707,
	 1361,  9812,  2949, 11265, 10301,  9108,   478,  6489,
	  101,  1911,  9483,  3608, 11997, 10536,   812,  8915,
	  637,  8159,  5299,  9128,  3512,  8290,  7068,  7922,
	 3036,  4759,  2163,  3937,  3755, 11306,  7739,  4922,
	11932,   424,  5538,  6228, 11131,  7778, 11974,  1097,
	 2890, 10027,  2569,  2250,  2352,   821,  2550, 11016,
	 7769,   136,   617,  3157,  5889,  9219,  6855,   120,
	 4405,  1825,  9635,  7214, 10261, 11393,  2441,  9562,
	11176,   599,  2085, 11465,  7233,  6177,  4801,  9926,
	 9010,  4514,  9455, 11352, 11670,  6174,  7950,  9766,
	 6896, 11603,  3213,  8473,  9873,  2835, 10422,  3732,
	 7961,  1457, 10857,  8069,   832,  1628,  3410,  4900,
	10855,  5111,  9543,  6325,  7431,  4083,  3072,  8847,
	 9853, 10122,  5259, 11413,  6556,   303,  1465,  3871,
	 4873,  5813, 10017,  6898,  3311,  5947,  8637,  5852,
	 3856,   928,  4933,  8530,  1871,  2184,  5571,  5879,
	 3481, 11597,  9511,  8153,    35,  2609,  5963,  8064,
	 1080, 12039,  8444,  3052,  3813, 11065,  6736,  8454,
	 2340,  7651,  1910, 10709,  2117,  9637,  6402,  6028,
	 2124,  7701,  2679,  5183,  6270,  7424,  2597,  6795,
	 9222, 10837,   280,  8583,  3270,  6753,  2354,  3779,
	 6102,  4732,  5926,  2497,  8640, 10289,  6107, 12127,
	 2958, 12287, 10292,  8086,   817,  4021,  2610,  1444,
	 5899, 11720,  3292,  2424,  5090,  7242,  5205,  5281,
	 9956,  2702,  6656,   735,  2243, 11656,   833,  3107,
	 6012,  6801,  1126,  6339,  5250, 10391,  9642,  5278,
	 3513,  9769,  3025,   779,  9433,  3392,  7437,   668,
	10184,  8111,  6527,  6568, 10831,  6482,  8263,  5711,
	 9780,   467,  5462,  4425, 11999,  1205,  5015,  6918,
	 5096,  3827,  5525, 11579,  3518,  4875,  7388,  1931,
	 6615,  1541,  8708,   260,  3385,  4792,  4391,  5697,
	 7895,  2155,  7337,   236, 10635, 11534,  1906,  4793,
	 9527,  7239,  8354,  5121, 10662,  2311,  3346,  8556,
	  707,  1088,  4936,   678, 10245,    18,  5684,   960,
	 4459,  7957,   226,  2451,     6,  8874,   320,  6298,
	 8963,  8735,  2852,  2981,  1707,  5408,  5017,  9876,
	 9790,  2968,  1899,  6729,  4183,  5290, 10084,  7679,
	 7941,  8744,  5694,  3461,  4175,  5747,  5561,  3378,
	 5227,   952,  4319,  9810,  4356,  3088, 11118,   840,
	 6257,   486,  6000,  1342, 10382,  6017,  4798,  5489,
	 4498,  4193,  2306,  6521,  1475,  6372,  9029,  8037,
	 1625,  7020,  4740,  5730,  7956,  6351,  6494,  6917,
	11405,  7487, 10202, 10155,  7666,  7556, 11509,  1546,
	 6571, 10199,  2265,  7327,  5824, 11396, 11581,  9722,
	 2251, 11199,  5356,  7408,  2861,  4003,  9215,   484,
	 7526,  9409, 12235,  6157,  9025,  2121, 10255,  2519,
	 9533,  3824,  8674, 11419, 10888,  4762, 11303,  4097,
	 2414,  6496,  9953, 10554,   808,  2999,  2130,  4286,
	12078,  7445,  5132,  7915,   245,  5974,  4874,  7292,
	 7560, 10539,  9952,  9075,  2113,  3721, 10285, 10022,
	 9578,  8934, 11074,  9498,   294,  4711,  3391,  1377,
	 9072, 10189,  4569, 10890,  9909,  6923,    53,  4653,
	  439, 10253,  7028, 10207,  8343,  1141,  2556,  7601,
	 8150, 10630,  8648,  9832,  7951, 11245,  2131,  5765,
	10343,  9781,  2718,  1419,  4531,  3844,  4066,  4293,
	11657, 11525, 11353,  4313,  4869, 12186,  1611, 10892,
	11489,  8833,  2393,    15, 10830,  5003,    17,   565,
	 5891, 12177, 11058, 10412,  8885,  3974, 10981,  7130,
	 5840, 10482,  8338,  6035,  6964,  1574, 10936,  2020,
	 2465,  8191,   384,  2642,  2729,  5399,  2175,  9396,
	11987,  8035,  4375,  6611,  5010, 11812,  9131, 11427,
	  104,  6348,  9643,  6757, 12110,  5617, 10935,   541,
	  135,  3041,  7200,  6526,  5085, 12136,   842,  4129,
	 7685, 11079,  8426,  1008,  2725, 11772,  6058,  1101,
	 1950,  8424,  5688,  6876, 12005, 10079,  5335,   927,
	 1770,   273,  8377,  2271,  5225, 10283,   116, 11807,
	   91, 11699,   757,  1304,  7524,  6451,  8032,  8154,
	 7456,  4191,   309,  2318,  2292, 10393, 11639,  9481,
	12238, 10594,  9569,  7912, 10368,  9889, 12244,  7179,
	 3924,  3188,   367,  2077,   336,  5384,  5631,  8596,
	 4621,  1775,  8866,   451,  6108,  1317,  6246,  8795,
	 5896,  7283,  3132, 11564,  4977, 12161,  7371,  1366,
	12130, 10619,  3809,  5149,  6300,  2638,  4197,  1418,
	10065,  4156,  8373,  8644, 10445,   882,  8158, 10173,
	 9763, 12191,   459,  2966,  3166,   405,  5000,  9311,
	 6404,  8986,  1551,  8175,  3630, 10766,  9265,   700,
	 8573,  9508,  6630, 11437, 11595,  5850,  3950,  4775,
	11941,  1446,  6018,  3386, 11470,  5310,  5476,   553,
	 9474,  2586,  1431,  2741,   473, 11383,  4745,   836,
	 4062, 10666,  7727, 11752,  5534,   312,  4307,  4351,
	 5764,  8679,  8381,  8187,     5,  7395,  4363,  1152,
	 5421,  5231,  6473,   436,  7567,  8603,  6229,  8230
};

/*
 * Tables for NTT and inverse NTT, ternary case.
 *
 *   GMt_square: for degree halving and doubling (inverse: iGMt_square)
 *   GMt_cubic: for ternary split/merge (inverse: iGMt_cubic)
 */

static const uint16_t GMt_square[] = {
	 9358,  9358,  8086, 11703,  5774, 14509, 12722,  9851,
	16750, 12828,  7852,   806,  1458, 10770,  9265, 12609,
	 8775,  1328, 14458, 11372,  1705,  1823,  7105,  6894,
	 9026,    72, 11666,  7057,  4201,  8427, 18263, 14143,
	11872,  6834,  4390,  7775, 13188, 11852, 17658,  7550,
	 8671,  4125, 12457, 11838, 14110,  5843,  1013, 16889,
	15905,  5600, 12331, 18417,  5191,  4134,  9307, 10416,
	  141, 17654, 14588, 12484,   374,  9438, 14640,  1869,
	17998, 16130, 13431, 13647,  6690,  6180, 12094,   509,
	12223, 13523,  4231,  1594,  5883,  7501, 10569, 12987,
	17487, 15162,  2004,   694,  7557,  9626,  4139,  9031,
	10013, 13052,  3184,  2280,  6819,   761, 10145,  8793,
	15397,  5792,   430,  6514,  4105,  8173, 14998, 17409,
	 9415, 15310,  5503, 14176,  9024,  5443, 11982,  6357,
	 4076,  3104,  1147,  7259,   876,  6926,  9056, 11672,
	 8610, 11260,  3662,  8921, 16955,  6074, 12328, 17257,
	18117,   700, 13062, 18431,  2953,  5125, 12684,  1302,
	 6930,  6815, 11040, 10777,  4655,  5788,  1830,  7146,
	 5330,  8726,  5778,  3767, 14007, 15171, 17287, 17705,
	16342,  2532, 17017,  5470, 15632, 10638,   166, 15032,
	 3832, 13211,  2833, 14024, 12256,  7850, 17450, 13144,
	14661,  9989,  6120,  6976,  3983,  4010, 15841, 11575,
	 8164, 10848,   398,   285, 12373, 16224, 17397, 17228,
	 7857, 15028, 12038,  3433,  9467,  4695, 15720, 13943,
	 4443,  3691, 16893,  6678,  1588, 11882,  7158,  2810,
	12578,  9470,  3440, 15246, 14407, 10085,  9386, 10241,
	 9408,  6459,  6609, 11726, 13581, 16348, 10863, 16069,
	14175,  6399,  9176,  2773,  7008,   109, 17149,  1211,
	15887, 17073, 15175, 12117, 16909,   576,  1163,  1157,
	 4969, 10459,  7517,  6448,  9389, 11401,  9611,  5076,
	 2811, 17806, 16687,  6901, 13339,  2651, 12233,  5101,
	14069, 14567,  7491,  2539,  2282,  9878,  8104,  6081
};

static const uint16_t GMt_cubic[] = {
	    0,     0,  5863, 13355,  3451, 10413, 17691,  5912,
	 1638, 13729,   651,  6638,  5184, 14889,  7732, 13716,
	 6193, 12464,  2225,  4481,  6221, 17110, 16888,  3019,
	18432,  3784, 17251, 11902,  2776,  2426,   158, 10417,
	 2894, 16739, 10603,  6889,  3044,  2129,  3573,  9590,
	 9271, 14968,  9120, 14929, 14605, 15247,  9822, 12913,
	 5467, 13131, 10444,   256, 12400,  8818,  2565,  8231,
	 1966,  7588,  1254, 10578, 16985,  4631,  2733, 17674,
	 8301, 17281,  5426,  2378, 16107,  9043, 15618, 16119,
	12790,  7698,  2720, 11567, 15351, 12632,  6810,   294,
	 3399,  4418, 17657,  5537,  2072, 12010, 15948,  2410,
	16169, 14064, 15170, 15515, 17644, 17863,  7485,  8281,
	14259, 15768,  6376,  2013, 11100,  6407, 14337, 15544,
	11571, 12144, 18069, 13334,  7623,  2213, 15082, 16713,
	 5319,  1740,  1405, 10617, 17722, 17639,  7516,  1575,
	 3339, 10262,  2036,   770,  2735, 10106,  6995,   708,
	10542, 16517, 18369,  2547,  7012, 10112, 11767,  7800,
	16536,  7811,  6572, 16102, 12667, 12305,  4798,   873,
	 2005,  7476, 10486,  7225,   886,  2182, 15004, 16937,
	 4939,  1886, 13070, 17292,  3488, 17869, 12257, 15373,
	 7292,  1273, 10933, 11613, 15275,  5288,  9143,  1629,
	11564,  1766,  9795,  4483,  8622,   762, 16188, 15900,
	14917, 14351,  9946,  4522,  9359, 13770,  2538, 18234,
	 6214,  6732,  8614, 12601,  3224,  3030, 13570,  5458,
	11553,  6524, 15226,  6374,  2292,  9015, 17926,  1456,
	 6036, 16696,   981, 11362, 18094, 10899,  4828, 16384,
	 2832, 11718, 11051,  7493,  9259,  5077, 13369, 10289,
	 4117, 15590, 18415, 12813, 18101,  2844, 13102,  6802,
	 4802,  4170, 17033,  7329, 15140,     4, 15470,  4728,
	11498, 11881,  5515, 15829,  7508, 13414,  8183,  2968,
	   81,  6857,  3577, 12887, 14773,  6257,  5635,  4141,
	 4355, 18215,  4803,   386,  2568, 15312, 12364, 16011,
	 9971,  2087,  7035, 15245,  6870, 12883,  9820,  2048,
	 9503,  3431,  6849,   182, 15728,  5405, 10032, 10892,
	 7427,  6557,  4606,  8514,  9175,  9572,  6246, 14675,
	12678,  7547, 17800, 17415, 12902,  7849,  6073,  5719,
	15262, 17614, 12210,  8891, 10155,  6285,  3327,   371,
	11109,  9217,  6542,   591, 18258, 17045, 14346, 18354,
	12065,  4581, 12121, 13873,   321,  1914, 10762, 13522,
	 8759, 16911, 12225,  7430, 16576,  3915, 16986,   847,
	11952,  8214,  7586, 13190,   648, 17990, 10183, 10931,
	 7690,  6747,  2111, 11898, 16407, 16689,  1558,  3088,
	 4854, 10165,  4765, 15147, 18252,  2883,  7254, 16034,
	 1550, 14927,  7233,  3333, 10522,    32, 13162,   958,
	18150,  1758, 15721, 13460, 11422,  4537,  7848, 17164,
	  259, 15326, 11210, 14126, 18336, 16821, 14377, 11648,
	13534, 12651, 15777,  4319, 14503, 14122, 18289, 10339,
	 4223,  1579, 14676,  4645,   340,  3750, 14787,  8580,
	10662,  4829, 12745, 12081,  5686, 13920, 11240, 11204,
	13430,   661,  3447,  7116,  8279,  8364, 16288,  6160,
	 5385, 10058,  5685, 17704,   403,  4987, 15521, 14507,
	 3474, 15546, 14142, 16104, 15068, 14390,  4098, 13754,
	12138,  4844,  6242, 11378,   436,  9146, 17661,  8834,
	 4719,  4881, 11092, 18246,  5919, 17032, 10151,  2988,
	10093,  1264,  3775,   975, 18425, 11839,  8977,  3051,
	13104, 17667,  5208, 16238, 10038,  6621, 12497, 10430,
	12967,  1518,  9171,  6275,  3257,  7189, 15710, 18218,
	10604,  3105, 17921,  1943,   797,  7164,  1971,  7101,
	11938,  5891,  9471, 13921,  2646, 15088, 12395,  9305,
	16040,  4509, 10156,  2501,  7088, 17456,  9434,  6465,
	 2304,   473, 13677,  6096,   347, 14128,  4628, 17431,
	 3037, 10184, 13732,   739, 11602,  5438, 17845, 13032,
	 9597, 16395,  7359,  5807, 12846, 16990, 13613,  8643,
	 8738,  4210,  5836, 17743,  1140, 17995,  1871, 16841
};

static const uint16_t iGMt_square[] = {
	 3318,   879,  6730, 10347,  8582,  5711,  3924, 12659,
	 5824,  9168,  7663, 16975, 17627, 10581,  5605,  1683,
	 4290,   170, 10006, 14232, 11376,  6767, 18361,  9407,
	11539, 11328, 16610, 16728,  7061,  3975, 17105,  9658,
	16564,  3793,  8995, 18059,  5949,  3845,   779, 18292,
	 8017,  9126, 14299, 13242,    16,  6102, 12833,  2528,
	 1544, 17420, 12590,  4323,  6595,  5976, 14308,  9762,
	10883,   775,  6581,  5245, 10658, 14043, 11599,  6561,
	 1176,  6105, 12359,  1478,  9512, 14771,  7173,  9823,
	 6761,  9377, 11507, 17557, 11174, 17286, 15329, 14357,
	12076,  6451, 12990,  9409,  4257, 12930,  3123,  9018,
	 1024,  3435, 10260, 14328, 11919, 18003, 12641,  3036,
	 9640,  8288, 17672, 11614, 16153, 15249,  5381,  8420,
	 9402, 14294,  8807, 10876, 17739, 16429,  3271,   946,
	 5446,  7864, 10932, 12550, 16839, 14202,  4910,  6210,
	17924,  6339, 12253, 11743,  4786,  5002,  2303,   435,
	12352, 10329,  8555, 16151, 15894, 10942,  3866,  4364,
	13332,  6200, 15782,  5094, 11532,  1746,   627, 15622,
	13357,  8822,  7032,  9044, 11985, 10916,  7974, 13464,
	17276, 17270, 17857,  1524,  6316,  3258,  1360,  2546,
	17222,  1284, 18324, 11425, 15660,  9257, 12034,  4258,
	 2364,  7570,  2085,  4852,  6707, 11824, 11974,  9025,
	 8192,  9047,  8348,  4026,  3187, 14993,  8963,  5855,
	15623, 11275,  6551, 16845, 11755,  1540, 14742, 13990,
	 4490,  2713, 13738,  8966, 15000,  6395,  3405, 10576,
	 1205,  1036,  2209,  6060, 18148, 18035,  7585, 10269,
	 6858,  2592, 14423, 14450, 11457, 12313,  8444,  3772,
	 5289,   983, 10583,  6177,  4409, 15600,  5222, 14601,
	 3401, 18267,  7795,  2801, 12963,  1416, 15901,  2091,
	  728,  1146,  3262,  4426, 14666, 12655,  9707, 13103,
	11287, 16603, 12645, 13778,  7656,  7393, 11618, 11503,
	17131,  5749, 13308, 15480,     2,  5371, 17733,   316
};

static const uint16_t iGMt_cubic[] = {
	    0,     0, 10467, 10693, 11779, 12521, 11471,  8020,
	12449,  4717,  8728,  3544, 12446, 11795,  6342,  4704,
	 8174,  8016,   350, 16007,  5349,  6531, 14648, 14649,
	13869, 15414,  7544,  1323, 16177, 13952, 12162,  5969,
	 3492,   759, 12354, 13802,  9109,  7855, 12811, 10845,
	12767, 10202,  3582,  9615, 10188, 18177, 10769,  5302,
	15342,  5520, 17791,  3186, 12624,  3504, 12736,  3465,
	12416,  8843,   915, 16304,  3714, 11544,  4588,  1694,
	 6287, 17725, 11062,  8327,  1266, 17663, 11510,  8171,
	 5941, 16858,    83,   794,  9221,  7816,  3579, 16693,
	16802,  1720,  5410, 16220,  4735,  5099, 17860,  6289,
	17226,  2889,  4693, 12026,  4363, 16420, 16924,  2665,
	17637, 10152, 18214,   570, 18088,  2918,  2105,  4369,
	13538, 16023,  8495,  6423, 12120, 12896, 17414, 14015,
	 6516, 18139,  2719,  5801,  9586,  6866,  5092, 10735,
	17932,  2314,  7064,  9390,  3048, 16055,  9453,  1152,
	14786,  2422,  5689,  3121,  4417, 18047,  4573,   218,
	 1494, 14292,  8516, 12176,  9123,  5546, 11657, 11576,
	 5215, 15465, 12527,  5019,  8119,  2604, 18050,  6552,
	10742, 13705, 15136, 18429,  9704, 11104,   632, 14263,
	 6300, 11631, 15257, 15589,  5602,  5620,  6960,  2843,
	 3080,  8144,  4182, 13356,  3558, 10940,  9547,  6715,
	 6877,  2049,  7195,  7534,  8052,  7071,  7773,  1737,
	16470, 16977, 11710,  9418,  8852, 12059,  5029, 11909,
	 8112, 12975,   194, 15403, 14446,  5832, 17915, 11701,
	 2737,   199, 14022,  4663,  5424, 13911,   566,  4082,
	  288,  2533,  7860, 17671,  5312, 13950,  9798, 16667,
	 7514, 16804,  9987, 13145, 17753,  6820,  6019, 17160,
	15317,  3060,  4052,   564, 14211,  1141,  3053, 16547,
	16500,  1496, 17137, 16251,  3261, 11208, 12962, 10957,
	 3925, 17560,   362,  6128,  8903,  2331,  8725, 10622,
	 3967, 10633, 15333,  8321, 15822, 15886, 12458,  1916,
	 3463,  1592,  1578,   438,  6526,   690,  4528, 14223,
	 4970,  9790, 14289,  1443,  1552, 12626, 11635,  2038,
	 4813,  5401,  6164, 12995, 12993, 17694, 11286,  8249,
	 5630,  1002,  4652,  4305,  7581, 12337,  1831, 17960,
	 2969, 11968,  8065,   977,  7655, 15932, 11531, 13924,
	 3090,  9128,  5991,  3345, 13983,  4512,  6047, 12542,
	13303, 11332, 12066, 11269, 15978, 16490,  7499, 15328,
	15925,   215, 14501, 11244,  2896, 12158, 11449, 16915,
	 2067,  8003,  3417, 11812,  7403,  2195, 13870,   766,
	 5926, 15382,  6586,  6594,  2800, 17458,  8829, 17169,
	 7163, 15445,  7320,  1401, 11279,   187, 18271, 13552,
	 8827,  9599,  9723,  9287, 13297,  7055,  7294, 13589,
	 8777,  4679,   678,  4043, 16471,  2329,  6361,  2887,
	 1014,  3926, 13849, 13446,  6414,   729, 13760,  8375,
	10128, 12273, 18348, 10069, 14764, 11317, 12769, 17772,
	   36,  7229, 10199,  4513,   664,  6352,  5833, 13604,
	 6207,  9853, 15023, 14683, 10031, 13788,  2644, 16854,
	 7950,  8094,   381,  4311, 11458, 14114,   883,  5782,
	 2729,  6785,  1515,  1612, 15517,  4307,  3366,  3107,
	 9117,  1269,  6885, 13896,  2261,  4973, 16392, 16675,
	12204, 17475, 10490, 18401,  3900, 15100,  5056,  3506,
	 9653,  2399, 15369, 15550,  8051,  3286, 13122,  8268,
	16903, 15345, 18151,  1744,  8646,  6535,   943, 11686,
	17685,  7502,  1091,   443, 12829,  5243,  3738, 10219,
	16139, 17586, 12661, 14518,  4795, 11003, 10281,  1522,
	15673,  4911, 16840, 16519, 16681,  4560,  7484, 13852,
	14425,    79,  1213,  1388,  5951, 17842,  1892,  9216,
	 2956, 18062,  3870, 12148,  3319,  9542, 16081,   819,
	  354, 12714,  5053, 10584,   385,  1018,  5131, 10886,
	10004,  3758, 18036,  8861, 14525,  9919,   870, 11876,
	17573,  7541, 10323, 13028,  6667, 18251,  6072, 15002,
	 7772, 16385, 12420,  5550, 10223,  3188,  7884, 16346
};

/*
 * Reduce a small signed integer modulo q. The source integer MUST
 * be between -q/2 and +q/2.
 */
static inline uint32_t
mq_conv_small(int x, uint32_t q)
{
	/*
	 * If x < 0, the cast to uint32_t will set the high bit to 1.
	 */
	uint32_t y;

	y = (uint32_t)x;
	y += q & -(y >> 31);
	return y;
}

/*
 * Addition modulo q. Operands must be in the 0..q-1 range.
 */
static inline uint32_t
mq_add(uint32_t x, uint32_t y, uint32_t q)
{
	/*
	 * We compute x + y - q. If the result is negative, then the
	 * high bit will be set, and 'd >> 31' will be equal to 1;
	 * thus '-(d >> 31)' will be an all-one pattern. Otherwise,
	 * it will be an all-zero pattern. In other words, this
	 * implements a conditional addition of q.
	 */
	uint32_t d;

	d = x + y - q;
	d += q & -(d >> 31);
	return d;
}

/*
 * Subtraction modulo q. Operands must be in the 0..q-1 range.
 */
static inline uint32_t
mq_sub(uint32_t x, uint32_t y, uint32_t q)
{
	/*
	 * As in mq_add(), we use a conditional addition to ensure the
	 * result is in the 0..q-1 range.
	 */
	uint32_t d;

	d = x - y;
	d += q & -(d >> 31);
	return d;
}

/*
 * Division by 2 modulo q. Operand must be in the 0..q-1 range.
 */
static inline uint32_t
mq_rshift1(uint32_t x, uint32_t q)
{
	x += q & -(x & 1);
	return (x >> 1);
}

/*
 * Montgomery multiplication modulo q. If we set R = 2^16 mod q, then
 * this function computes: x * y / R mod q
 * Operands must be in the 0..q-1 range.
 */
static inline uint32_t
mq_montymul(uint32_t x, uint32_t y, uint32_t q, uint32_t q0i)
{
	uint32_t z, w;

	/*
	 * We compute x*y + k*q with a value of k chosen so that the 16
	 * low bits of the result are 0. We can then shift the value.
	 * After the shift, result may still be larger than q, but it
	 * will be lower than 2*q, so a conditional subtraction works.
	 */

	z = x * y;
	w = ((z * q0i) & 0xFFFF) * q;

	/*
	 * When adding z and w, the result will have its low 16 bits
	 * equal to 0. Since x, y and z are lower than q, the sum will
	 * be no more than (2^15 - 1) * q + (q - 1)^2, which will
	 * fit on 29 bits.
	 */
	z = (z + w) >> 16;

	/*
	 * After the shift, analysis shows that the value will be less
	 * than 2q. We do a subtraction then conditional subtraction to
	 * ensure the result is in the expected range.
	 */
	z -= q;
	z += q & -(z >> 31);
	return z;
}

/*
 * Montgomery squaring (computes (x^2)/R).
 */
static inline uint32_t
mq_montysqr(uint32_t x, uint32_t q, uint32_t q0i)
{
	return mq_montymul(x, x, q, q0i);
}

/*
 * Divide x by y modulo q = 12289.
 */
static inline uint32_t
mq_div_12289(uint32_t x, uint32_t y)
{
	/*
	 * We invert y by computing y^(q-2) mod q.
	 *
	 * We use the following addition chain for exponent e = 12287:
	 *
	 *   e0 = 1
	 *   e1 = 2 * e0 = 2
	 *   e2 = e1 + e0 = 3
	 *   e3 = e2 + e1 = 5
	 *   e4 = 2 * e3 = 10
	 *   e5 = 2 * e4 = 20
	 *   e6 = 2 * e5 = 40
	 *   e7 = 2 * e6 = 80
	 *   e8 = 2 * e7 = 160
	 *   e9 = e8 + e2 = 163
	 *   e10 = e9 + e8 = 323
	 *   e11 = 2 * e10 = 646
	 *   e12 = 2 * e11 = 1292
	 *   e13 = e12 + e9 = 1455
	 *   e14 = 2 * e13 = 2910
	 *   e15 = 2 * e14 = 5820
	 *   e16 = e15 + e10 = 6143
	 *   e17 = 2 * e16 = 12286
	 *   e18 = e17 + e0 = 12287
	 *
	 * Additions on exponents are converted to Montgomery
	 * multiplications. We define all intermediate results as so
	 * many local variables, and let the C compiler work out which
	 * must be kept around.
	 */
	uint32_t y0, y1, y2, y3, y4, y5, y6, y7, y8, y9;
	uint32_t y10, y11, y12, y13, y14, y15, y16, y17, y18;

	y0 = mq_montymul(y, R2b, Qb, Q0Ib);
	y1 = mq_montysqr(y0, Qb, Q0Ib);
	y2 = mq_montymul(y1, y0, Qb, Q0Ib);
	y3 = mq_montymul(y2, y1, Qb, Q0Ib);
	y4 = mq_montysqr(y3, Qb, Q0Ib);
	y5 = mq_montysqr(y4, Qb, Q0Ib);
	y6 = mq_montysqr(y5, Qb, Q0Ib);
	y7 = mq_montysqr(y6, Qb, Q0Ib);
	y8 = mq_montysqr(y7, Qb, Q0Ib);
	y9 = mq_montymul(y8, y2, Qb, Q0Ib);
	y10 = mq_montymul(y9, y8, Qb, Q0Ib);
	y11 = mq_montysqr(y10, Qb, Q0Ib);
	y12 = mq_montysqr(y11, Qb, Q0Ib);
	y13 = mq_montymul(y12, y9, Qb, Q0Ib);
	y14 = mq_montysqr(y13, Qb, Q0Ib);
	y15 = mq_montysqr(y14, Qb, Q0Ib);
	y16 = mq_montymul(y15, y10, Qb, Q0Ib);
	y17 = mq_montysqr(y16, Qb, Q0Ib);
	y18 = mq_montymul(y17, y0, Qb, Q0Ib);

	/*
	 * Final multiplication with x, which is not in Montgomery
	 * representation, computes the correct division result.
	 */
	return mq_montymul(y18, x, Qb, Q0Ib);
}

/*
 * Divide x by y modulo q = 18433.
 */
static inline uint32_t
mq_div_18433(uint32_t x, uint32_t y)
{
	/*
	 * We invert y by computing y^(q-2) mod q.
	 *
	 * We use the following addition chain for exponent e = 18431:
	 *
	 *   e0             = 1
	 *   e1  = 2 * e0   = 2
	 *   e2  = e1 + e0  = 3
	 *   e3  = 2 * e2   = 6
	 *   e4  = e3 + e0  = 7
	 *   e5  = 2 * e4   = 14
	 *   e6  = 2 * e5   = 28
	 *   e7  = e6 + e4  = 35
	 *   e8  = e7 + e6  = 63
	 *   e9  = 2 * e8   = 126
	 *   e10 = 2 * e9   = 252
	 *   e11 = e10 + e7 = 287
	 *   e12 = 2 * e11  = 574
	 *   e13 = 2 * e12  = 1148
	 *   e14 = 2 * e13  = 2296
	 *   e15 = 2 * e14  = 4592
	 *   e16 = 2 * e15  = 9184
	 *   e17 = 2 * e16  = 18368
	 *   e18 = e17 + e8 = 18431
	 *
	 * Additions on exponents are converted to Montgomery
	 * multiplications. We define all intermediate results as so
	 * many local variables, and let the C compiler work out which
	 * must be kept around.
	 */
	uint32_t y0, y1, y2, y3, y4, y5, y6, y7, y8, y9;
	uint32_t y10, y11, y12, y13, y14, y15, y16, y17, y18;

	y0  = mq_montymul(y, R2t, Qt, Q0It);          
	y1  = mq_montysqr(y0, Qt, Q0It);
	y2  = mq_montymul(y1, y0, Qt, Q0It);
	y3  = mq_montysqr(y2, Qt, Q0It);
	y4  = mq_montymul(y3, y0, Qt, Q0It);
	y5  = mq_montysqr(y4, Qt, Q0It);
	y6  = mq_montysqr(y5, Qt, Q0It);
	y7  = mq_montymul(y6, y4, Qt, Q0It);
	y8  = mq_montymul(y7, y6, Qt, Q0It);
	y9  = mq_montysqr(y8, Qt, Q0It);
	y10 = mq_montysqr(y9, Qt, Q0It);
	y11 = mq_montymul(y10, y7, Qt, Q0It);
	y12 = mq_montysqr(y11, Qt, Q0It);
	y13 = mq_montysqr(y12, Qt, Q0It);
	y14 = mq_montysqr(y13, Qt, Q0It);
	y15 = mq_montysqr(y14, Qt, Q0It);
	y16 = mq_montysqr(y15, Qt, Q0It);
	y17 = mq_montysqr(y16, Qt, Q0It);
	y18 = mq_montymul(y17, y8, Qt, Q0It);

	/*
	 * Final multiplication with x, which is not in Montgomery
	 * representation, computes the correct division result.
	 */
	return mq_montymul(y18, x, Qt, Q0It);
}

/*
 * Compute NTT on a ring element, binary case.
 */
static void
mq_NTT_binary(uint16_t *a, unsigned logn)
{
	size_t n, t, m;

	n = (size_t)1 << logn;
	t = n;
	for (m = 1; m < n; m <<= 1) {
		size_t ht, i, j1;

		ht = t >> 1;
		for (i = 0, j1 = 0; i < m; i ++, j1 += t) {
			size_t j, j2;
			uint32_t s;

			s = GMb[m + i];
			j2 = j1 + ht;
			for (j = j1; j < j2; j ++) {
				uint32_t u, v;

				u = a[j];
				v = mq_montymul(a[j + ht], s, Qb, Q0Ib);
				a[j] = (uint16_t)mq_add(u, v, Qb);
				a[j + ht] = (uint16_t)mq_sub(u, v, Qb);
			}
		}
		t = ht;
	}
}

/*
 * Compute the inverse NTT on a ring element, binary case.
 */
static void
mq_iNTT_binary(uint16_t *a, unsigned logn)
{
	size_t n, t, m;
	uint32_t ni;

	n = (size_t)1 << logn;
	t = 1;
	m = n;
	while (m > 1) {
		size_t hm, dt, i, j1;

		hm = m >> 1;
		dt = t << 1;
		for (i = 0, j1 = 0; i < hm; i ++, j1 += dt) {
			size_t j, j2;
			uint32_t s;

			j2 = j1 + t;
			s = iGMb[hm + i];
			for (j = j1; j < j2; j ++) {
				uint32_t u, v, w;

				u = a[j];
				v = a[j + t];
				a[j] = (uint16_t)mq_add(u, v, Qb);
				w = mq_sub(u, v, Qb);
				a[j + t] = (uint16_t)
					mq_montymul(w, s, Qb, Q0Ib);
			}
		}
		t = dt;
		m = hm;
	}

	/*
	 * To complete the inverse NTT, we must now divide all values by
	 * n (the vector size). We thus need the inverse of n, i.e. we
	 * need to divide 1 by 2 logn times. But we also want it in
	 * Montgomery representation, i.e. we also want to multiply it
	 * by R = 2^16. In the common case, this should be a simple right
	 * shift. The loop below is generic and works also in corner cases;
	 * its computation time is negligible.
	 */
	ni = Rb;
	for (m = n; m > 1; m >>= 1) {
		ni = mq_rshift1(ni, Qb);
	}
	for (m = 0; m < n; m ++) {
		a[m] = (uint16_t)mq_montymul(a[m], ni, Qb, Q0Ib);
	}
}

/*
 * Compute NTT on a ring element, ternary case.
 */
static void
mq_NTT_ternary(uint16_t *a, unsigned logn)
{
	size_t n, hn, u, v, t, m;
	uint32_t r, w;

	n = (size_t)3 << (logn - 1);
	hn = n >> 1;

	/*
	 * Modulo X^2-X+1.
	 */
	r = GMt_square[1];
	for (u = 0; u < hn; u ++) {
		uint32_t a0, a1, b;

		a0 = a[u];
		a1 = a[u + hn];
		b = mq_montymul(a1, r, Qt, Q0It);
		a[u] = mq_add(a0, b, Qt);
		a[u + hn] = mq_sub(mq_add(a0, a1, Qt), b, Qt);
	}

	/*
	 * Intermediate steps for degree doubling.
	 */
	t = hn;
	for (m = 2; t > 3; m <<= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v2;
			uint32_t s;

			s = GMt_square[m + u1];
			v2 = v1 + ht;
			for (v = v1; v < v2; v ++) {
				uint32_t a0, a1;

				a0 = a[v];
				a1 = a[v + ht];
				a1 = mq_montymul(a1, s, Qt, Q0It);
				a[v] = mq_add(a0, a1, Qt);
				a[v + ht] = mq_sub(a0, a1, Qt);
			}
		}
		t = ht;
	}

	/*
	 * Degree tripling.
	 */
	w = mq_montymul(GMt_square[1], GMt_square[1], Qt, Q0It);
	for (u = 0, v = (size_t)1 << (logn - 1); u < n; u += 3, v ++) {
		uint32_t fA, fB, fC, x, x2;
		uint32_t fB0, fB1, fB2, fC0, fC1, fC2;

		fA = a[u + 0];
		fB = a[u + 1];
		fC = a[u + 2];
		x = GMt_cubic[v];
		x2 = mq_montysqr(x, Qt, Q0It);
		fB0 = mq_montymul(fB, x, Qt, Q0It);
		fB1 = mq_montymul(fB0, w, Qt, Q0It);
		fB2 = mq_montymul(fB1, w, Qt, Q0It);
		fC0 = mq_montymul(fC, x2, Qt, Q0It);
		fC1 = mq_montymul(fC0, w, Qt, Q0It);
		fC2 = mq_montymul(fC1, w, Qt, Q0It);
		a[u + 0] = mq_add(fA, mq_add(fB0, fC0, Qt), Qt);
		a[u + 1] = mq_add(fA, mq_add(fB1, fC2, Qt), Qt);
		a[u + 2] = mq_add(fA, mq_add(fB2, fC1, Qt), Qt);
	}
}

/*
 * Compute the inverse NTT on a ring element, ternary case.
 */
static void
mq_iNTT_ternary(uint16_t *a, unsigned logn)
{
	size_t n, hn, u, v, t, m;
	uint32_t r, w, ni;

	n = (size_t)3 << (logn - 1);
	hn = n >> 1;

	/*
	 * Dividing degree by 3.
	 */
	w = mq_montymul(iGMt_square[1], iGMt_square[1], Qt, Q0It);
	for (u = 0, v = (size_t)1 << (logn - 1); u < n; u += 3, v ++) {
		uint32_t f0, f1, f2, x, x2;
		uint32_t f11, f12, f21, f22;

		f0 = a[u + 0];
		f1 = a[u + 1];
		f2 = a[u + 2];
		x = iGMt_cubic[v];
		x2 = mq_montysqr(x, Qt, Q0It);
		f11 = mq_montymul(f1, w, Qt, Q0It);
		f12 = mq_montymul(f11, w, Qt, Q0It);
		f21 = mq_montymul(f2, w, Qt, Q0It);
		f22 = mq_montymul(f21, w, Qt, Q0It);
		a[u + 0] = mq_add(f0, mq_add(f1, f2, Qt), Qt);
		a[u + 1] = mq_montymul(x,
			mq_add(f0, mq_add(f11, f22, Qt), Qt), Qt, Q0It);
		a[u + 2] = mq_montymul(x2,
			mq_add(f0, mq_add(f12, f21, Qt), Qt), Qt, Q0It);
	}

	/*
	 * Intermediate steps for degree halving.
	 */
	t = 6;
	for (m = (size_t)1 << (logn - 2); t < n; m >>= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v2;
			uint32_t s;

			s = iGMt_square[m + u1];
			v2 = v1 + ht;
			for (v = v1; v < v2; v ++) {
				uint32_t a0, a1;

				a0 = a[v];
				a1 = a[v + ht];
				a[v] = mq_add(a0, a1, Qt);
				a[v + ht] = mq_montymul(
					mq_sub(a0, a1, Qt), s, Qt, Q0It);
			}
		}
		t <<= 1;
	}

	/*
	 * Modulo X^2-X+1.
	 */
	r = iGMt_square[0];
	for (u = 0; u < hn; u ++) {
		uint32_t a0, a1, b;

		a0 = a[u];
		a1 = a[u + hn];
		b = mq_montymul(r, mq_sub(a0, a1, Qt), Qt, Q0It);
		a[u] = mq_sub(mq_add(a0, a1, Qt), b, Qt);
		a[u + hn] = mq_add(b, b, Qt);
	}

	/*
	 * Corrective factor: all values have been (cumulatively)
	 * multiplied by n. Inverses of n modulo q have been precomputed.
	 */
	ni = INVNQt[logn];
	for (u = 0; u < n; u ++) {
		a[u] = mq_montymul(a[u], ni, Qt, Q0It);
	}
}

static void
mq_NTT(uint16_t *a, unsigned logn, int ternary)
{
	if (ternary) {
		mq_NTT_ternary(a, logn);
	} else {
		mq_NTT_binary(a, logn);
	}
}

static void
mq_iNTT(uint16_t *a, unsigned logn, int ternary)
{
	if (ternary) {
		mq_iNTT_ternary(a, logn);
	} else {
		mq_iNTT_binary(a, logn);
	}
}

/*
 * Convert a polynomial (mod q) to Montgomery representation.
 */
static void
mq_poly_tomonty(uint16_t *f, unsigned logn, int ternary)
{
	size_t u, n;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		for (u = 0; u < n; u ++) {
			f[u] = (uint16_t)mq_montymul(f[u], R2t, Qt, Q0It);
		}
	} else {
		n = (size_t)1 << logn;
		for (u = 0; u < n; u ++) {
			f[u] = (uint16_t)mq_montymul(f[u], R2b, Qb, Q0Ib);
		}
	}
}

/*
 * Multiply two polynomials together (NTT representation, and using
 * a Montgomery multiplication). Result f*g is written over f.
 */
static void
mq_poly_montymul_ntt(uint16_t *f, const uint16_t *g, unsigned logn, int ternary)
{
	size_t u, n;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		for (u = 0; u < n; u ++) {
			f[u] = (uint16_t)mq_montymul(f[u], g[u], Qt, Q0It);
		}
	} else {
		n = (size_t)1 << logn;
		for (u = 0; u < n; u ++) {
			f[u] = (uint16_t)mq_montymul(f[u], g[u], Qb, Q0Ib);
		}
	}
}

/*
 * Subtract polynomial g from polynomial f.
 */
static void
mq_poly_sub(uint16_t *f, const uint16_t *g, unsigned logn, int ternary)
{
	size_t u, n;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		for (u = 0; u < n; u ++) {
			f[u] = (uint16_t)mq_sub(f[u], g[u], Qt);
		}
	} else {
		n = (size_t)1 << logn;
		for (u = 0; u < n; u ++) {
			f[u] = (uint16_t)mq_sub(f[u], g[u], Qb);
		}
	}
}

/* ===================================================================== */

/*
 * Falcon verification context: it contains the decoded public key,
 * and the running hash context.
 */
struct falcon_vrfy_ {
	shake_context sc;
	uint16_t h[1024];
	unsigned logn;
	int ternary;
};

/* see falcon.h */
falcon_vrfy *
falcon_vrfy_new(void)
{
	falcon_vrfy *fv;

	fv = malloc(sizeof *fv);
	if (fv == NULL) {
		return NULL;
	}
	fv->logn = 0;
	fv->ternary = 0;
	return fv;
}

/* see falcon.h */
void
falcon_vrfy_free(falcon_vrfy *fv)
{
	if (fv != NULL) {
		free(fv);
	}
}

/* see falcon.h */
int
falcon_vrfy_set_public_key(falcon_vrfy *fv,
	const void *pkey, size_t len)
{
	const unsigned char *buf;
	unsigned fb;

	buf = pkey;

	/*
	 * Read first byte: it defines the modulus and degree:
	 *   t 000 dddd
	 *   ^ ^^^ ^^^^
	 *   |  |    |
	 *   |  |    +----- degree log, over four bits (1 to 10 only)
	 *   |  |
	 *   |  |
	 *   |  |
	 *   |  +---------- reserved, must be 0
	 *   |
	 *   +------------- 1 for ternary, 0 for binary
	 */
	if (len <= 1) {
		goto bad_pkey;
	}
	fb = *buf ++;
	len --;
	fv->logn = fb & 0x0F;
	if ((fb >> 7) != 0) {
		fv->ternary = 1;
		if (fv->logn < 2 || fv->logn > 9) {
			goto bad_pkey;
		}
	} else {
		fv->ternary = 0;
		if (fv->logn < 1 || fv->logn > 10) {
			goto bad_pkey;
		}
	}
	if (((fb >> 4) & 0x07) != 0) {
		goto bad_pkey;
	}

	/*
	 * Decode public vector.
	 */
	if (fv->ternary) {
		if (falcon_decode_18433(fv->h, fv->logn, buf, len) != len) {
			goto bad_pkey;
		}
	} else {
		if (falcon_decode_12289(fv->h, fv->logn, buf, len) != len) {
			goto bad_pkey;
		}
	}

	/*
	 * We apply NTT and Montgomery representation immediately, since
	 * it will be used for signature verification.
	 * (Conceptually this could be part of the public key encoding,
	 * but it would require making both NTT and Montgomery
	 * representations part of the specification.)
	 */
	mq_NTT(fv->h, fv->logn, fv->ternary);
	mq_poly_tomonty(fv->h, fv->logn, fv->ternary);
	return 1;

bad_pkey:
	fv->logn = 0;
	return 0;
}

/* see falcon.h */
void
falcon_vrfy_start(falcon_vrfy *fv, const void *r, size_t rlen)
{
	/*
	 * We use SHAKE-256, which has an internal capacity of 512 bits.
	 */
	shake_init(&fv->sc, 512);
	shake_inject(&fv->sc, r, rlen);
}

/* see falcon.h */
void
falcon_vrfy_update(falcon_vrfy *fv, const void *data, size_t len)
{
	shake_inject(&fv->sc, data, len);
}

/* see internal.h */
int
falcon_vrfy_verify_raw(const uint16_t *c0, const int16_t *s2,
	const uint16_t *h, unsigned logn, int ternary)
{
	uint16_t x[1024];
	size_t u, n;
	uint32_t q;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		q = Qt;
	} else {
		n = (size_t)1 << logn;
		q = Qb;
	}

	/*
	 * Reduce s2 elements modulo q ([0..q-1] range).
	 */
	for (u = 0; u < n; u ++) {
		uint32_t w;

		w = (uint32_t)s2[u];
		w += q & -(w >> 31);
		x[u] = (uint16_t)w;
	}

	/*
	 * Compute s1 = s2*h - c0 mod phi mod q (in x[]).
	 */
	mq_NTT(x, logn, ternary);
	mq_poly_montymul_ntt(x, h, logn, ternary);
	mq_iNTT(x, logn, ternary);
	mq_poly_sub(x, c0, logn, ternary);

	/*
	 * Normalize s1 elements into the [-q/2..q/2] range.
	 */
	for (u = 0; u < n; u ++) {
		int32_t w;

		w = (int32_t)x[u];
		w -= (int32_t)(q & -(((q >> 1) - (uint32_t)w) >> 31));
		((int16_t *)x)[u] = (int16_t)w;
	}

	/*
	 * Signature is valid if and only if the aggregate (s1,s2) vector
	 * is short enough.
	 */
	return falcon_is_short((int16_t *)x, s2, logn, ternary);
}

/* see falcon.h */
int
falcon_vrfy_verify(falcon_vrfy *fv, const void *sig, size_t len)
{
	const unsigned char *sig_buf;
	unsigned q;
	int fb;
	uint16_t c0[1024];
	int16_t s2[1024];

	/*
	 * Public key must have been set.
	 */
	if (fv->logn == 0) {
		return -2;
	}

	/*
	 * Signature cannot be too short.
	 */
	if (len <= 2) {
		return -1;
	}

	/*
	 * Read first byte: it defines the modulus and degree:
	 *   t cc 0 dddd
	 *   ^ ^^ ^ ^^^^
	 *   |  | |   |
	 *   |  | |   +----- degree log, over four bits (1 to 10 only)
	 *   |  | |
	 *   |  | +--------- reserved, must be 0
	 *   |  |
	 *   |  +----------- compression type
	 *   |
	 *   +-------------- 1 for ternary, 0 for binary
	 *
	 * Compression is:
	 *   00   uncompressed, 16 bits per integer (signed)
	 *   01   compressed with static codes
	 * Other compression values are reserved.
	 */
	sig_buf = sig;
	fb = *sig_buf ++;
	len --;

	/* Check reserved bit. */
	if ((fb & 0x10) != 0) {
		return -1;
	}

	/* Check degree. */
	if ((fb & 0x0F) != fv->logn) {
		return -1;
	}
	if ((fb >> 7) != fv->ternary) {
		return -1;
	}
	q = fv->ternary ? Qt : Qb;

	/* Decode value. */
	if (falcon_decode_small(s2, fv->logn,
		(fb >> 5) & 0x03, q, sig_buf, len) != len)
	{
		return -1;
	}

	/*
	 * Hash the message into a vector, then verify the signature.
	 */
	shake_flip(&fv->sc);
	falcon_hash_to_point(&fv->sc, q, c0, fv->logn);
	return (int)falcon_vrfy_verify_raw(
		c0, s2, fv->h, fv->logn, fv->ternary);
}

/* see internal.h */
int
falcon_compute_public(uint16_t *h,
	const int16_t *f, const int16_t *g, unsigned logn, int ternary)
{
	size_t u, n;
	uint16_t t[1024];
	uint32_t q;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		q = Qt;
	} else {
		n = (size_t)1 << logn;
		q = Qb;
	}
	for (u = 0; u < n; u ++) {
		t[u] = mq_conv_small(f[u], q);
		h[u] = mq_conv_small(g[u], q);
	}
	mq_NTT(h, logn, ternary);
	mq_NTT(t, logn, ternary);
	for (u = 0; u < n; u ++) {
		if (t[u] == 0) {
			return 0;
		}
		h[u] = ternary
			? mq_div_18433(h[u], t[u])
			: mq_div_12289(h[u], t[u]);
	}
	mq_iNTT(h, logn, ternary);
	return 1;
}

/* see internal.h */
int
falcon_complete_private(int16_t *G,
	const int16_t *f, const int16_t *g, const int16_t *F,
	unsigned logn, int ternary)
{
	size_t u, n;
	uint16_t t1[1024], t2[1024];
	uint32_t q;

	if (ternary) {
		n = (size_t)3 << (logn - 1);
		q = Qt;
	} else {
		n = (size_t)1 << logn;
		q = Qb;
	}
	for (u = 0; u < n; u ++) {
		t1[u] = mq_conv_small(g[u], q);
		t2[u] = mq_conv_small(F[u], q);
	}
	mq_NTT(t1, logn, ternary);
	mq_NTT(t2, logn, ternary);
	mq_poly_tomonty(t1, logn, ternary);
	mq_poly_montymul_ntt(t1, t2, logn, ternary);
	for (u = 0; u < n; u ++) {
		t2[u] = mq_conv_small(f[u], q);
	}
	mq_NTT(t2, logn, ternary);
	for (u = 0; u < n; u ++) {
		if (t2[u] == 0) {
			return 0;
		}
		t1[u] = ternary
			? mq_div_18433(t1[u], t2[u])
			: mq_div_12289(t1[u], t2[u]);
	}
	mq_iNTT(t1, logn, ternary);
	for (u = 0; u < n; u ++) {
		uint32_t w;

		w = t1[u];
		G[u] = (int32_t)w - (int32_t)(q & ~-((w - (q >> 1)) >> 31));
	}
	return 1;
}
